{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import cv2\n",
    "#采用sklearn.svm.SVC，类似的有sklearn.svm.LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图片尺寸过大，进行降采样\n",
      "图片尺寸过大，进行降采样\n",
      "data size 32718848\n"
     ]
    }
   ],
   "source": [
    "def creat_tag_list(txtList):\n",
    "    '''读取各行数据并录入对应列表'''\n",
    "    tagDict = {'numStr':[],'sex':[],'age':[],'race':[],'face':[],'prop':[]}\n",
    "    for line in txtList:\n",
    "        if line.find('missing descriptor') == -1: # 没有缺失卷标才录入\n",
    "            tagDict['numStr'].append(line[1:5])\n",
    "            for keyName in tagDict.keys():\n",
    "                if keyName != 'numStr':\n",
    "                    list_append(tagDict,line,keyName)\n",
    "    le = LabelEncoder()\n",
    "    for keyName in tagDict.keys():\n",
    "        if keyName in ['sex','age','race','face']:\n",
    "            tagDict[keyName] = np.array(tagDict[keyName])\n",
    "            # tagDict[keyName] = le.fit_transform(tagDict[keyName]) # 转换为编码\n",
    "    return tagDict\n",
    "\n",
    "def list_append(tagDict,line,tagStr):\n",
    "    '''读取一个数据加入列表中'''\n",
    "    idx = line.find(tagStr)\n",
    "    if tagStr == 'prop': # 格式特殊，单独处理\n",
    "        idxR = line.find(')',idx)\n",
    "        idxL = line.find('(',idx) # 找出左括号\n",
    "    else:\n",
    "        idxR = line.find(')',idx)\n",
    "        idxL = line.rfind(' ',0,idxR) # 空格所在的索引\n",
    "    tagDict[tagStr].append(line[idxL+1:idxR])\n",
    "    if tagDict[tagStr][-1] == '':\n",
    "        tagDict[tagStr][-1] = 'null'\n",
    "\n",
    "def read_tag(tagFile):\n",
    "    '''读取tag文件'''\n",
    "    file = open(tagFile,mode='r')\n",
    "    txtList = file.readlines() # 包含各行文本的列表\n",
    "    file.close()\n",
    "    tagDict = creat_tag_list(txtList) # 讲对应类别信息录入各列表中\n",
    "    return tagDict\n",
    "\n",
    "def read_data(dataPath,tagDict):\n",
    "    dataList = []\n",
    "    for fileName in tagDict['numStr']:\n",
    "        curData = read_1data(dataPath,fileName)\n",
    "        if len(read_1data(dataPath,fileName)) != 128*128:\n",
    "            print('图片尺寸过大，进行降采样')\n",
    "            curData = curData.reshape(512,512)\n",
    "            curData = cv2.pyrDown(curData,curData)\n",
    "            curData = cv2.pyrDown(curData,curData)\n",
    "            curData = curData.flatten()\n",
    "        dataList.append(curData)\n",
    "    dataList = np.vstack(dataList)\n",
    "    return dataList\n",
    "\n",
    "def read_1data(dataPath,fileName):\n",
    "    '''读取tag文件'''\n",
    "    curPath = dataPath+'\\\\'+fileName\n",
    "    with open(curPath, 'rb') as f:\n",
    "        content = f.read()\n",
    "    # 将字节数组转成 128*128 的图像\n",
    "    data = np.frombuffer(content, dtype=np.uint8)\n",
    "    # data = data.reshape(128,128)\n",
    "    # cv2.imshow('real', data.reshape(128,128))\n",
    "    # cv2.waitKey(0)\n",
    "    return data\n",
    "\n",
    "'''读取文件、标签'''\n",
    "dataPath1 = 'D:\\\\py\\\\PatternRecognition\\\\final\\\\人脸图像识别\\\\face\\\\rawdataDR'\n",
    "dataPath2 = 'D:\\\\py\\\\PatternRecognition\\\\final\\\\人脸图像识别\\\\face\\\\rawdataDS'\n",
    "tagFile1 = 'D:\\\\py\\\\PatternRecognition\\\\final\\\\人脸图像识别\\\\face\\\\faceDR'\n",
    "tagFile2 = 'D:\\\\py\\\\PatternRecognition\\\\final\\\\人脸图像识别\\\\face\\\\faceDS'\n",
    "h,w = 128,128 # 图片长宽\n",
    "tagDict1 = read_tag(tagFile1)\n",
    "read_1data(dataPath1,tagDict1['numStr'][0])\n",
    "data1 = read_data(dataPath1,tagDict1)\n",
    "print('data size',data1.size)\n",
    "X1 = data1\n",
    "\n",
    "# 加载DS数据集\n",
    "tagDict2 = read_tag(tagFile2)\n",
    "read_1data(dataPath2,tagDict2['numStr'][0])\n",
    "data2 = read_data(dataPath2,tagDict2)\n",
    "X2 = data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 shape (1997, 300)\n",
      "X2 shape (1996, 300)\n"
     ]
    }
   ],
   "source": [
    "'''提取特征'''\n",
    "X1 = data1\n",
    "X2 = data2\n",
    "'''LLE'''\n",
    "n_components = 300\n",
    "lle = LocallyLinearEmbedding(n_components=n_components, n_neighbors=100, random_state=42)\n",
    "X1_reduced = lle.fit_transform(X1)\n",
    "X1 = X1_reduced\n",
    "print('X1 shape',X1.shape)\n",
    "\n",
    "X2_reduced = lle.fit_transform(X2)\n",
    "X2 = X2_reduced\n",
    "print('X2 shape',X2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-cross:0.78(+/- 0.02) train:0.85 test:0.75 [knn]\n",
      "AUC-cross:0.82(+/- 0.02) train:1.00 test:0.75 [rf]\n",
      "AUC-cross:0.85(+/- 0.02) train:0.97 test:0.79 [SVC]\n",
      "AUC-cross:0.72(+/- 0.03) train:0.72 test:0.66 [g Naive Bayes]\n",
      "AUC-cross:0.73(+/- 0.05) train:0.80 test:0.69 [b Naive Bayes]\n",
      "AUC-cross:0.84(+/- 0.03) train:0.86 test:0.77 [sgd]\n"
     ]
    }
   ],
   "source": [
    "'''二分类，各种分类器'''\n",
    "clf_knn = KNeighborsClassifier()\n",
    "clf_rf = RandomForestClassifier()\n",
    "# clf_SVC = SVC(kernel='linear')\n",
    "clf_SVC = SVC(kernel='rbf', probability=True)\n",
    "clf_gNB = GaussianNB()\n",
    "clf_bNB = BernoulliNB()\n",
    "clf_sgd = SGDClassifier(random_state=42)\n",
    "\n",
    "'''单个数据集交叉验证'''\n",
    "keyName = 'sex'\n",
    "# 划分数据集和测试集\n",
    "# X_train, X_test, y_train, y_test = train_test_split\\\n",
    "#     (np.vstack((X1,X2)), np.hstack((tagDict1[keyName],tagDict2[keyName])), test_size=test_size, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split\\\n",
    "    (X1, tagDict1[keyName], test_size=test_size, random_state=0)\n",
    "# X_train, X_test, y_train, y_test = X1,X2,tagDict1[keyName],tagDict2[keyName]\n",
    "for clf, label in \\\n",
    "    zip([clf_knn,clf_rf,clf_SVC,clf_gNB,clf_bNB,clf_sgd], \\\n",
    "        ['knn','rf','SVC','g Naive Bayes','b Naive Bayes','sgd']):\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy_train = clf.score(X_train, y_train)\n",
    "    accuracy_test = clf.score(X_test, y_test)\n",
    "    print(\"AUC-cross:%0.2f(+/- %0.2f) train:%0.2f test:%0.2f [%s]\" % (scores.mean(), scores.std(), accuracy_train, accuracy_test, label))\n",
    "    # print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-cross:0.90(+/- 0.01) train:1.00 test:0.84 [stacking]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.81      0.77      0.79       473\n",
      "        male       0.86      0.88      0.87       725\n",
      "\n",
      "    accuracy                           0.84      1198\n",
      "   macro avg       0.83      0.83      0.83      1198\n",
      "weighted avg       0.84      0.84      0.84      1198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''二分类'''\n",
    "keyName = 'sex'\n",
    "X_train, X_test, y_train, y_test = train_test_split\\\n",
    "    (np.vstack((X1,X2)), np.hstack((tagDict1[keyName],tagDict2[keyName])), test_size=test_size, random_state=0)\n",
    "# X_train, X_test, y_train, y_test = X1,X2,tagDict1[keyName],tagDict2[keyName]\n",
    "'''stacking'''\n",
    "lr = LogisticRegression()\n",
    "# RFC = RandomForestClassifier(n_estimators=100\n",
    "#     , min_impurity_decrease=0.0025\n",
    "#     , random_state= 420, n_jobs=8)\n",
    "RFC = RandomForestClassifier()\n",
    "f_esti = lr\n",
    "stacking = StackingClassifier(estimators=\\\n",
    "    [('KNN',clf_knn), ('rf',clf_rf), ('SVC',clf_SVC), ('gNB',clf_gNB), ('bNB',clf_bNB), ('sgd',clf_sgd)],  final_estimator=f_esti)\n",
    "scores = cross_val_score(stacking, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "stacking.fit(X_train,y_train)\n",
    "accuracy_train = stacking.score(X_train, y_train)\n",
    "accuracy_test = stacking.score(X_test, y_test)\n",
    "print(\"AUC-cross:%0.2f(+/- %0.2f) train:%0.2f test:%0.2f [%s]\" % (scores.mean(), scores.std(), accuracy_train, accuracy_test, 'stacking'))\n",
    "print(classification_report(y_test, stacking.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-cross:0.73(+/- 0.02) train:0.65 test:0.62 [linear]\n",
      "AUC-cross:0.86(+/- 0.01) train:0.78 test:0.71 [poly]\n",
      "AUC-cross:0.85(+/- 0.01) train:0.91 test:0.80 [rbf]\n",
      "AUC-cross:0.64(+/- 0.02) train:0.64 test:0.62 [sigmoid]\n"
     ]
    }
   ],
   "source": [
    "'''SVC调参'''\n",
    "keyName = 'sex'\n",
    "X_train, X_test, y_train, y_test = train_test_split\\\n",
    "    (np.vstack((X1,X2)), np.hstack((tagDict1[keyName],tagDict2[keyName])), test_size=test_size, random_state=0)\n",
    "scoresList = []\n",
    "for k in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "    # clf = SVC(kernel=k, probability=True)\n",
    "    clf = SVC(kernel=k)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "    clf.fit(X_train,y_train)\n",
    "    accuracy_train = clf.score(X_train, y_train)\n",
    "    accuracy_test = clf.score(X_test, y_test)\n",
    "    print(\"AUC-cross:%0.2f(+/- %0.2f) train:%0.2f test:%0.2f [%s]\" % (scores.mean(), scores.std(), accuracy_train, accuracy_test, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.88 test:0.82 [knn]\n",
      "train:1.00 test:0.81 [rf]\n",
      "train:0.79 test:0.78 [SVC]\n",
      "train:0.67 test:0.64 [g Naive Bayes]\n",
      "train:0.85 test:0.78 [b Naive Bayes]\n",
      "train:0.82 test:0.79 [sgd]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "'''多分类，各种分类器'''\n",
    "clf_knn = KNeighborsClassifier()\n",
    "clf_rf = RandomForestClassifier()\n",
    "# clf_SVC = SVC(kernel='linear')\n",
    "clf_SVC = SVC(kernel='sigmoid', probability=True)\n",
    "clf_gNB = GaussianNB()\n",
    "clf_bNB = BernoulliNB()\n",
    "clf_sgd = SGDClassifier(random_state=42)\n",
    "\n",
    "'''指定数据、目标值'''\n",
    "keyName = 'age'\n",
    "X_train, X_test, y_train, y_test = train_test_split\\\n",
    "    (np.vstack((X1,X2)), np.hstack((tagDict1[keyName],tagDict2[keyName])), test_size=test_size, random_state=0)\n",
    "# X_train, X_test, y_train, y_test = X1,X2,tagDict1[keyName],tagDict2[keyName]\n",
    "\n",
    "for clf, label in \\\n",
    "    zip([clf_knn,clf_rf,clf_SVC,clf_gNB,clf_bNB,clf_sgd], \\\n",
    "        ['knn','rf','SVC','g Naive Bayes','b Naive Bayes','sgd']):\n",
    "    \n",
    "    if clf in [clf_SVC]:\n",
    "        clf = OneVsRestClassifier(clf)\n",
    "        # clf = OneVsOneClassifier(clf)\n",
    "        # clf = OutputCodeClassifier(clf, code_size=2, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy_train = clf.score(X_train, y_train)\n",
    "    accuracy_test = clf.score(X_test, y_test)\n",
    "    print(\"train:%0.2f test:%0.2f [%s]\" % (accuracy_train, accuracy_test, label))\n",
    "    # print('       ',label)\n",
    "    # print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.98 test:0.85 [stacking]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       adult       0.89      0.96      0.92       943\n",
      "       child       0.59      0.50      0.54        96\n",
      "      senior       0.89      0.48      0.62        52\n",
      "        teen       0.57      0.40      0.47       107\n",
      "\n",
      "    accuracy                           0.85      1198\n",
      "   macro avg       0.73      0.59      0.64      1198\n",
      "weighted avg       0.84      0.85      0.84      1198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''多分类'''\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "'''指定数据、目标值'''\n",
    "keyName = 'age'\n",
    "X_train, X_test, y_train, y_test = train_test_split\\\n",
    "    (np.vstack((X1,X2)), np.hstack((tagDict1[keyName],tagDict2[keyName])), test_size=test_size, random_state=0)\n",
    "# X_train, X_test, y_train, y_test = X1,X2,tagDict1[keyName],tagDict2[keyName]\n",
    "'''stacking'''\n",
    "lr = LogisticRegression()\n",
    "RFC = RandomForestClassifier()\n",
    "f_esti = RFC\n",
    "stacking = StackingClassifier(estimators=[('KNN',clf_knn), ('SVC',clf_SVC)],  final_estimator=f_esti)\n",
    "stacking.fit(X_train,y_train)\n",
    "accuracy_train = stacking.score(X_train,y_train)\n",
    "accuracy_test = stacking.score(X_test,y_test)\n",
    "print(\"train:%0.2f test:%0.2f [%s]\" % (accuracy_train, accuracy_test, 'stacking'))\n",
    "print(classification_report(y_test, stacking.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''LLE调参'''\n",
    "nCo_a,nCo_b,nCo_step = 20,60,10\n",
    "nNei_a,nNei_b,nNei_step = 5,55,10\n",
    "\n",
    "rNum = int((nCo_b-nCo_a)/nCo_step)\n",
    "cNum = int((nNei_b-nNei_a)/nNei_step)\n",
    "scoresDict = {'avg':np.zeros([rNum,cNum]),'knn':np.zeros([rNum,cNum]),'rf':np.zeros([rNum,cNum]),\\\n",
    "    'SVC':np.zeros([rNum,cNum]),'g Naive Bayes':np.zeros([rNum,cNum]),'b Naive Bayes':np.zeros([rNum,cNum]),\\\n",
    "            'sgd':np.zeros([rNum,cNum])}\n",
    "\n",
    "i = 0\n",
    "for n_components in range(nCo_a,nCo_b,nCo_step):\n",
    "    j = 0\n",
    "    for n_neighbors in range(nNei_a,nNei_b,nNei_step):\n",
    "        X1 = data1\n",
    "        X2 = data2\n",
    "        '''提取特征'''\n",
    "        '''LLE'''\n",
    "        lle = LocallyLinearEmbedding(n_components=n_components, n_neighbors=n_neighbors, random_state=42)\n",
    "        X1_reduced = lle.fit_transform(X1)\n",
    "        X1 = X1_reduced\n",
    "        X2_reduced = lle.fit_transform(X2)\n",
    "        X2 = X2_reduced\n",
    "\n",
    "        '''二分类，各种分类器'''\n",
    "        clf_knn = KNeighborsClassifier()\n",
    "        clf_rf = RandomForestClassifier(n_estimators=30)\n",
    "        # clf_SVC = SVC(kernel='linear')\n",
    "        clf_SVC = SVC(kernel='rbf', probability=True)\n",
    "        clf_gNB = GaussianNB()\n",
    "        clf_bNB = BernoulliNB()\n",
    "        clf_sgd = SGDClassifier(random_state=42)\n",
    "\n",
    "        '''单个数据集交叉验证'''\n",
    "        keyName = 'sex'\n",
    "        # 划分数据集和测试集\n",
    "        X_train, X_test, y_train, y_test = train_test_split\\\n",
    "            (np.vstack((X1,X2)), np.hstack((tagDict1[keyName],tagDict2[keyName])), test_size=test_size, random_state=0)\n",
    "        # X_train, X_test, y_train, y_test = X1,X2,tagDict1[keyName],tagDict2[keyName]\n",
    "        scoresList = [] # 记录一次的平均AUC\n",
    "        for clf, label in \\\n",
    "            zip([clf_knn,clf_rf,clf_SVC,clf_gNB,clf_bNB,clf_sgd], \\\n",
    "                ['knn','rf','SVC','g Naive Bayes','b Naive Bayes','sgd']):\n",
    "            scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "            clf.fit(X_train, y_train)\n",
    "            accuracy_train = clf.score(X_train, y_train)\n",
    "            accuracy_test = clf.score(X_test, y_test)\n",
    "            scoresList.append(scores.mean())\n",
    "            scoresDict[label][i,j] = scores.mean()\n",
    "            # print(\"AUC-cross:%0.2f(+/- %0.2f) train:%0.2f test:%0.2f [%s]\" % (scores.mean(), scores.std(), accuracy_train, accuracy_test, label))\n",
    "            # print(classification_report(y_test, clf.predict(X_test)))\n",
    "        scoresDict['avg'][i,j] = np.mean(scoresList)\n",
    "        print('=======>n_components,n_neighbors',n_components,n_neighbors)\n",
    "        for label in ['avg','knn','rf','SVC','g Naive Bayes','b Naive Bayes','sgd']:\n",
    "            print(label,scoresDict[label][i,j])\n",
    "        j += 1\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 64-bit ('lane_detect': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06e6174a31cc8026049f7d855609ea519bbf1e2ce114ecb92f382d466c274703"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
